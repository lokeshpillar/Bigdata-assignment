#!/usr/bin/env python
# coding: utf-8

# In[1]:


# Install the Cassandra python driver
get_ipython().system('pip install cassandra-driver')


# In[2]:


# Import the necessary libraries
from cassandra.cluster import Cluster
from cassandra.auth import PlainTextAuthProvider
import json


# In[9]:


# This secure connect bundle is autogenerated when you download your SCB,
# if yours is different update the file name below
cloud_config= {
  'secure_connect_bundle': 'secure-connect-rowan.zip'
}

# This token JSON file is autogenerated when you download your token,
# if yours is different update the file name below
with open("rowan-token.json") as f:
    secrets = json.load(f)

    CLIENT_ID = "YGdMEKJlBMBPflgZNNHDeSCP"
    CLIENT_SECRET = "oKj+DFBI0Crp-S7dkP5QXELf8MteD8BNZ4bfXmTEwLi,ONIb2znQXArKMAtWnvJ7xw.T3Jg8kExnfJh54rdJSXmqStkvDBCqxSpM5.bgiSa_MfZT7ABuZ9P22jwY08N6"


auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)
cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)
session = cluster.connect()

if session:
  print('Connected!')
else:
  print("An error occurred.")


# In[11]:


session.set_keyspace('bigdata')  # Replace 'your_keyspace' with the correct name
print(f"Connected to keyspace: {session.keyspace}")


# In[12]:


rows = session.execute("SELECT table_name FROM system_schema.tables WHERE keyspace_name = 'bigdata'")
print("Existing tables:")
for row in rows:
    print(row.table_name)


# In[13]:


# Get a list of all tables in the keyspace
rows = session.execute("SELECT table_name FROM system_schema.tables WHERE keyspace_name = 'bigdata'")

# Drop each table
for row in rows:
    table_name = row.table_name
    try:
        session.execute(f"DROP TABLE IF EXISTS {table_name};")
        print(f"Table {table_name} dropped successfully.")
    except Exception as e:
        print(f"Error dropping table {table_name}: {e}")


# In[14]:


session.execute("""
CREATE TABLE IF NOT EXISTS sales_bronze (
    region TEXT,
    country TEXT,
    item_type TEXT,
    sales_channel TEXT,
    order_priority TEXT,
    order_date TEXT,
    order_id UUID PRIMARY KEY,
    ship_date TEXT,
    units_sold INT,
    unit_price FLOAT,
    unit_cost FLOAT,
    total_revenue FLOAT,
    total_cost FLOAT,
    total_profit FLOAT
);
""")
print("Table sales_bronze created successfully.")


# In[15]:


url = '/Users/lokeshreddy/Downloads/sales_100.csv'  # Replace with the actual file name after upload


# In[ ]:





# In[23]:


import pandas as pd
import uuid

# Load data from CSV into a DataFrame
file_path = '/Users/lokeshreddy/Downloads/sales_100.csv'
df = pd.read_csv(file_path)

# Iterate over the DataFrame rows
for _, row in df.iterrows():
    session.execute("""
        INSERT INTO sales_bronze (
            region, country, item_type, sales_channel, order_priority,
            order_date, order_id, ship_date, units_sold, unit_price,
            unit_cost, total_revenue, total_cost, total_profit
        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
    """, (
        row['Region'], 
        row['Country'], 
        row['Item Type'], 
        row['Sales Channel'],
        row['Order Priority'], 
        row['Order Date'], 
        uuid.uuid4(),  # Pass the UUID object directly
        row['Ship Date'], 
        row['UnitsSold'],  # Ensure this matches your actual column name
        row['UnitPrice'],
        row['UnitCost'], 
        row['TotalRevenue'], 
        row['TotalCost'], 
        row['TotalProfit']
    ))

print("Data inserted into sales_bronze.")


# In[24]:


rows = session.execute("SELECT * FROM sales_bronze LIMIT 10;")
for row in rows:
    print(row)


# In[25]:


import pandas as pd

# Load the CSV file into a DataFrame
file_path = '/Users/lokeshreddy/Downloads/sales_100.csv'
df = pd.read_csv(file_path)
 # Replace with the correct path to your file

# Check for missing (null) values
null_values = df.isnull().sum()

# Print the columns with missing values
print(null_values)


# In[26]:


session.execute("""
CREATE TABLE IF NOT EXISTS sales_silver (
    order_id UUID PRIMARY KEY,
    region TEXT,
    country TEXT,
    item_type TEXT,
    total_profit FLOAT
);
""")
print("Table sales_silver created successfully.")


# In[27]:


rows = session.execute("SELECT order_id, region, country, item_type, total_profit FROM sales_bronze;")
for row in rows:
    session.execute("""
        INSERT INTO sales_silver (order_id, region, country, item_type, total_profit)
        VALUES (%s, %s, %s, %s, %s)
    """, (row.order_id, row.region, row.country, row.item_type, row.total_profit))

print("Data successfully inserted into sales_silver.")


# In[28]:


session.execute("""
CREATE TABLE IF NOT EXISTS sales_silver (
    order_id UUID PRIMARY KEY,
    region TEXT,
    country TEXT,
    item_type TEXT,
    total_profit FLOAT
);
""")
print("Table sales_silver created successfully.")


# In[29]:


rows = session.execute("SELECT order_id, region, country, item_type, total_profit FROM sales_bronze;")
for row in rows:
    session.execute("""
        INSERT INTO sales_silver (order_id, region, country, item_type, total_profit)
        VALUES (%s, %s, %s, %s, %s)
    """, (row.order_id, row.region, row.country, row.item_type, row.total_profit))

print("Data successfully inserted into sales_silver.")


# In[30]:


session.execute("""
CREATE TABLE IF NOT EXISTS sales_by_region (
    region TEXT PRIMARY KEY,
    total_profit FLOAT
);
""")
print("Table sales_by_region created successfully.")



# In[31]:


import pandas as pd

# Step 1: Load data from sales_bronze
query = "SELECT region, total_profit FROM sales_bronze"
rows = session.execute(query)

# Convert the data into a Pandas DataFrame for easy aggregation
df = pd.DataFrame(rows)

# Step 2: Perform the aggregation in Python
aggregated_data = df.groupby('region', as_index=False).agg({'total_profit': 'sum'})

# Step 3: Insert aggregated data into the sales_by_region table
for index, row in aggregated_data.iterrows():
    session.execute("""
        INSERT INTO sales_by_region (region, total_profit)
        VALUES (%s, %s)
    """, (row['region'], row['total_profit']))

print("Data successfully inserted into sales_by_region.")


# In[32]:


session.execute("""
CREATE TABLE IF NOT EXISTS sales_by_region (
    region TEXT PRIMARY KEY,
    total_profit FLOAT
);
""")
print("Table sales_by_region created successfully.")




# In[33]:


import pandas as pd

# Step 1: Load data from sales_bronze (assuming you have a 'sales_bronze' table)
query = "SELECT region, total_profit FROM sales_bronze"
rows = session.execute(query)

# Convert to Pandas DataFrame for easy aggregation
df = pd.DataFrame(rows)

# Step 2: Aggregate data by 'region'
aggregated_data = df.groupby('region', as_index=False).agg({'total_profit': 'sum'})

# Step 3: Insert the aggregated data into the sales_by_region table
for index, row in aggregated_data.iterrows():
    session.execute("""
        INSERT INTO sales_by_region (region, total_profit)
        VALUES (%s, %s)
    """, (row['region'], row['total_profit']))

print("Data successfully inserted into sales_by_region.")


# In[34]:


session.execute("""
CREATE TABLE IF NOT EXISTS sales_by_item_type (
    item_type TEXT PRIMARY KEY,
    total_units_sold INT
);
""")
print("Table sales_by_item_type created successfully.")



# In[35]:


import pandas as pd

# Step 1: Load data from sales_bronze (assuming you have a 'sales_bronze' table)
query = "SELECT item_type, units_sold FROM sales_bronze"
rows = session.execute(query)

# Convert to Pandas DataFrame for easy aggregation
df = pd.DataFrame(rows)

# Step 2: Aggregate data by 'item_type'
aggregated_data = df.groupby('item_type', as_index=False).agg({'units_sold': 'sum'})

# Step 3: Insert the aggregated data into the sales_by_item_type table
for index, row in aggregated_data.iterrows():
    session.execute("""
        INSERT INTO sales_by_item_type (item_type, total_units_sold)
        VALUES (%s, %s)
    """, (row['item_type'], row['units_sold']))

print("Data successfully inserted into sales_by_item_type.")


# In[36]:


session.execute("""
CREATE TABLE IF NOT EXISTS monthly_sales_summary (
    order_date TEXT PRIMARY KEY,
    total_revenue FLOAT
);
""")
print("Table monthly_sales_summary created successfully.")



# In[37]:


import pandas as pd

# Step 1: Retrieve data from sales_bronze (assuming you have the 'sales_bronze' table)
query = "SELECT order_date, total_revenue FROM sales_bronze"
rows = session.execute(query)

# Convert to Pandas DataFrame for easy aggregation
df = pd.DataFrame(rows)

# Step 2: Aggregate data by 'order_date'
aggregated_data = df.groupby('order_date', as_index=False).agg({'total_revenue': 'sum'})

# Step 3: Insert the aggregated data into the monthly_sales_summary table
for index, row in aggregated_data.iterrows():
    session.execute("""
        INSERT INTO monthly_sales_summary (order_date, total_revenue)
        VALUES (%s, %s)
    """, (row['order_date'], row['total_revenue']))

print("Data successfully inserted into monthly_sales_summary.")


# In[38]:


# Query Gold tables and print results
tables = ["sales_by_region", "sales_by_item_type", "monthly_sales_summary"]

for table in tables:
    print(f"Data from {table}:")
    rows = session.execute(f"SELECT * FROM {table};")
    for row in rows:
        print(row)


# In[40]:


import pandas as pd

# Load the data
file_path = '/Users/lokeshreddy/Downloads/sales_100.csv'
df = pd.read_csv(file_path)

# Convert the 'Order Date' and 'Ship Date' columns to datetime format
df['Order Date'] = pd.to_datetime(df['Order Date'], errors='coerce', dayfirst=True)
df['Ship Date'] = pd.to_datetime(df['Ship Date'], errors='coerce', dayfirst=True)

# Check the cleaned data
print(df[['Order Date', 'Ship Date']].head())


# In[41]:


# Query for Bronze table
bronze_query = "SELECT * FROM sales_bronze;"
bronze_data = session.execute(bronze_query)

print("------ Bronze Table Data ------")
for row in bronze_data:
    print(row)

# Query for Silver table
silver_query = "SELECT * FROM sales_silver;"
silver_data = session.execute(silver_query)

print("\n------ Silver Table Data ------")
for row in silver_data:
    print(row)




# In[ ]:




